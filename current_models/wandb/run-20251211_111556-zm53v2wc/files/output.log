labels[0][:40]: tensor([  101,  2917,  2003,  2019,  7899,  2008,  5577,  1037,  4708,  1010,
        12739,  2007,  2019,  7953,  2008,  3640,  2582,  6123,  1012,  4339,
         1037,  3433,  2008, 23263, 28123,  1996,  5227,  1012,  1001,  1001,
         1001,  7899,  1024, 11506,  1996,  2445,  2616,  2362,  2046,  1037])
unique labels: tensor([    0,   101,   102,  1000,  1001,  1005,  1006,  1007,  1010,  1011,
         1012,  1015,  1016,  1017,  1018,  1019,  1024,  1029,  1037,  1038,
         1045,  1046,  1055,  1996,  1997,  1998,  1999,  2000,  2003,  2007,
         2008,  2011,  2012,  2015,  2017,  2019,  2022,  2023,  2024,  2029,
         2030,  2031,  2033,  2045,  2046,  2049,  2052,  2054,  2058,  2062,
         2064,  2070,  2071,  2092,  2094,  2096,  2100,  2102,  2104,  2109,
         2110,  2114,  2121,  2129,  2179,  2182,  2195,  2224,  2226,  2228,
         2317,  2323,  2362,  2368,  2396,  2411,  2421,  2424,  2433,  2445,
         2474,  2488,  2507,  2522,  2529,  2543,  2566,  2571,  2582,  2616,
         2622,  2627,  2653,  2714,  2791,  2804,  2829,  2836,  2896,  2917,
         2944,  2950,  3012,  3020,  3025,  3073,  3367,  3433,  3538,  3556,
         3600,  3640,  3698,  3793,  3857,  3899,  4141,  4248,  4339,  4419,
         4431,  4488,  4521,  4708,  4838,  5227,  5449,  5461,  5468,  5577,
         5674,  5761,  5886,  5939,  6123,  6149,  6251,  6651,  6873,  7013,
         7099,  7655,  7899,  7953,  8823,  8828,  9312, 10127, 10697, 10936,
        11506, 11916, 12034, 12046, 12247, 12369, 12739, 12978, 13599, 13971,
        14246, 14523, 16014, 16157, 16371, 17636, 18816, 19386, 19857, 20217,
        20253, 21923, 22953, 23263, 25370, 25854, 26163, 28123, 29458])
ignore_index in CE: -100
Synthetic test loss: 0.0
step=0000 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20858.4MB mem_reserved=22770.9MB
step=0001 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.0MB mem_peak=20902.1MB mem_reserved=23274.2MB
step=0002 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.1MB mem_reserved=23274.2MB
step=0003 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.9MB mem_reserved=23274.2MB
step=0004 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.9MB mem_reserved=23274.2MB
step=0005 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.9MB mem_reserved=23274.2MB
step=0006 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.9MB mem_reserved=23274.2MB
step=0007 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.9MB mem_reserved=23274.2MB
step=0008 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.9MB mem_reserved=23274.2MB
step=0009 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16715.8MB mem_peak=20902.9MB mem_reserved=23274.2MB
Traceback (most recent call last):
  File "/orcd/home/002/hyewona/lr-act/current_models/baseline_model_v2.py", line 294, in <module>
    main()
    ~~~~^^
  File "/orcd/home/002/hyewona/lr-act/current_models/baseline_model_v2.py", line 271, in main
    "loss": float(loss.item()),
                  ~~~~~~~~~^^
KeyboardInterrupt
