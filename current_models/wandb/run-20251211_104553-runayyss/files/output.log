Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51760/51760 [00:23<00:00, 2174.97 examples/s]
step=0000 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20856.0MB mem_reserved=22770.9MB
step=0001 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16712.6MB mem_peak=20899.7MB mem_reserved=23274.2MB
step=0002 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0003 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0004 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0005 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0006 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0007 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0008 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0009 | loss=0.0000 | lr=5.00e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0010 | loss=0.0000 | lr=4.99e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0011 | loss=0.0000 | lr=4.99e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0012 | loss=0.0000 | lr=4.99e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0013 | loss=0.0000 | lr=4.99e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23274.2MB
step=0014 | loss=0.0000 | lr=4.99e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23341.3MB
step=0015 | loss=0.0000 | lr=4.99e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23341.3MB
step=0016 | loss=0.0000 | lr=4.99e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23341.3MB
step=0017 | loss=0.0000 | lr=4.98e-05 | grad_norm=0.00 | mem_alloc=16713.4MB mem_peak=20900.5MB mem_reserved=23341.3MB
Traceback (most recent call last):
  File "/orcd/home/002/hyewona/lr-act/current_models/baseline_model_v2.py", line 272, in <module>
    main()
    ~~~~^^
  File "/orcd/home/002/hyewona/lr-act/current_models/baseline_model_v2.py", line 236, in main
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "/orcd/home/002/hyewona/lr-act/lora/lib/python3.13/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/orcd/home/002/hyewona/lr-act/lora/lib/python3.13/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/orcd/home/002/hyewona/lr-act/lora/lib/python3.13/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
KeyboardInterrupt
